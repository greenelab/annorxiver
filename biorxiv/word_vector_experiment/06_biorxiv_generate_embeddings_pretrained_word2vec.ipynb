{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate BioRxiv Document Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to generate document embeddings for every article in bioRxiv. After submitting my manuscript to PLOS Biology, I got a comment on why I chose not to use Doc2Vec to generate document vectors. With that being said this notebook will explore using Doc2Vec on bioRxiv to see if any of my results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T20:25:53.618451Z",
     "start_time": "2021-08-31T20:25:51.292985Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm_notebook\n",
    "import umap\n",
    "\n",
    "from annorxiver_modules.document_helper import DocIterator, generate_doc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T20:25:53.739390Z",
     "start_time": "2021-08-31T20:25:53.619881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_type</th>\n",
       "      <th>heading</th>\n",
       "      <th>category</th>\n",
       "      <th>document</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regular article</td>\n",
       "      <td>new results</td>\n",
       "      <td>genetics</td>\n",
       "      <td>440735_v1.xml</td>\n",
       "      <td>10.1101/440735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regular article</td>\n",
       "      <td>new results</td>\n",
       "      <td>systems biology</td>\n",
       "      <td>775270_v1.xml</td>\n",
       "      <td>10.1101/775270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regular article</td>\n",
       "      <td>new results</td>\n",
       "      <td>genetics</td>\n",
       "      <td>242404_v1.xml</td>\n",
       "      <td>10.1101/242404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regular article</td>\n",
       "      <td>new results</td>\n",
       "      <td>neuroscience</td>\n",
       "      <td>872994_v1.xml</td>\n",
       "      <td>10.1101/2019.12.11.872994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>regular article</td>\n",
       "      <td>new results</td>\n",
       "      <td>developmental biology</td>\n",
       "      <td>080853_v2.xml</td>\n",
       "      <td>10.1101/080853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_type      heading               category       document  \\\n",
       "0  regular article  new results               genetics  440735_v1.xml   \n",
       "1  regular article  new results        systems biology  775270_v1.xml   \n",
       "2  regular article  new results               genetics  242404_v1.xml   \n",
       "3  regular article  new results           neuroscience  872994_v1.xml   \n",
       "4  regular article  new results  developmental biology  080853_v2.xml   \n",
       "\n",
       "                         doi  \n",
       "0             10.1101/440735  \n",
       "1             10.1101/775270  \n",
       "2             10.1101/242404  \n",
       "3  10.1101/2019.12.11.872994  \n",
       "4             10.1101/080853  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal_map_df = pd.read_csv(\n",
    "    \"../exploratory_data_analysis/output/biorxiv_article_metadata.tsv\", sep=\"\\t\"\n",
    ")\n",
    "journal_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T20:25:53.742934Z",
     "start_time": "2021-08-31T20:25:53.740984Z"
    }
   },
   "outputs": [],
   "source": [
    "biorxiv_xpath_str = \"//abstract/p|//abstract/title|//abstract/sec/*|//body/sec//p|//body/sec//title|//body/p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T20:28:09.198201Z",
     "start_time": "2021-08-31T20:25:53.744405Z"
    }
   },
   "outputs": [],
   "source": [
    "model = api.load(\"word2vec-google-news-300\")\n",
    "model.save_word2vec_format(\"output/pretrained_output/temp_model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section trains the word2vec model (continuous bag of words [CBOW]). Since the number of dimensions can vary I decided to train multiple models: 150, 250, 300. Each model is saved into is own respective directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T06:43:23.745830Z",
     "start_time": "2021-09-01T14:10:25.672511Z"
    }
   },
   "outputs": [],
   "source": [
    "word_embedding_sizes = [300]\n",
    "doc_iterator = DocIterator(\"output/word2vec_input/biorxiv_text.txt\")\n",
    "for size in word_embedding_sizes:\n",
    "\n",
    "    # Create save path\n",
    "    word_path = Path(\"output/pretrained_output\")\n",
    "    word_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # If model exists don't run again\n",
    "    if Path(f\"{str(word_path.resolve())}/biorxiv_{size}.model\").exists():\n",
    "        continue\n",
    "\n",
    "    # Create model with biorxiv\n",
    "    model = Word2Vec(size=300, min_count=1)\n",
    "    model.build_vocab(doc_iterator)\n",
    "\n",
    "    # inject model with pretrained vectors\n",
    "    model.intersect_word2vec_format(\n",
    "        \"output/pretrained_output/temp_model.bin\", binary=True, lockf=1.0\n",
    "    )\n",
    "\n",
    "    # Run Word2Vec\n",
    "    model.train(doc_iterator, epochs=20, total_examples=model.corpus_count)\n",
    "\n",
    "# Save the model for future use\n",
    "model.save(f\"{str(word_path.resolve())}/biorxiv_{size}_pretrained.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T06:43:35.567618Z",
     "start_time": "2021-09-05T06:43:23.747362Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load(f\"{str(word_path.resolve())}/biorxiv_{size}_pretrained.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T23:32:05.402558Z",
     "start_time": "2021-09-05T23:32:05.395935Z"
    }
   },
   "outputs": [],
   "source": [
    "if not Path(\n",
    "    \"output/word2vec_output/biorxiv_all_articles_300_pretrained.tsv.xz\"\n",
    ").exists():\n",
    "    biorxiv_document_map = {\n",
    "        document: generate_doc_vector(\n",
    "            model,\n",
    "            document_path=f\"../biorxiv_articles/{document}\",\n",
    "            xpath=biorxiv_xpath_str,\n",
    "        )\n",
    "        for document in tqdm_notebook(journal_map_df.document.tolist())\n",
    "    }\n",
    "\n",
    "    biorxiv_vec_df = (\n",
    "        pd.DataFrame.from_dict(biorxiv_document_map, orient=\"index\")\n",
    "        .rename(columns={col: f\"feat_{col}\" for col in range(int(300))})\n",
    "        .rename_axis(\"document\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    biorxiv_vec_df.to_csv(\n",
    "        \"output/word2vec_output/biorxiv_all_articles_300_pretrained.tsv.xz\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "        compression=\"xz\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T23:32:10.132784Z",
     "start_time": "2021-09-05T23:32:10.127352Z"
    }
   },
   "outputs": [],
   "source": [
    "n_components = 2\n",
    "random_state = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T01:38:50.180250Z",
     "start_time": "2021-09-06T01:38:48.629150Z"
    }
   },
   "outputs": [],
   "source": [
    "reducer = PCA(n_components=n_components, random_state=random_state)\n",
    "\n",
    "embedding = reducer.fit_transform(\n",
    "    biorxiv_vec_df.dropna()[[f\"feat_{idx}\" for idx in range(300)]].values\n",
    ")\n",
    "\n",
    "pca_df = (\n",
    "    pd.DataFrame(embedding, columns=[\"pca1\", \"pca2\"])\n",
    "    .assign(document=[str(tag) for tag in biorxiv_vec_df.dropna().document.values])\n",
    "    .merge(journal_map_df[[\"category\", \"document\", \"doi\"]], on=\"document\")\n",
    ")\n",
    "\n",
    "pca_df.to_csv(\n",
    "    \"output/embedding_output/pca/biorxiv_pca_300_pretrained.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP the Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating document embeddings, the next step is to visualize all the documents. In order to visualize the embeddings a low dimensional representation is needed. UMAP is an algorithm that can generate this representation, while grouping similar embeddings together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T01:39:19.241241Z",
     "start_time": "2021-09-06T01:39:19.233931Z"
    }
   },
   "outputs": [],
   "source": [
    "random_state = 100\n",
    "n_neighbors = journal_map_df.category.unique().shape[0]\n",
    "n_components = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T01:41:00.352894Z",
     "start_time": "2021-09-06T01:39:19.242717Z"
    }
   },
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(\n",
    "    n_components=n_components, n_neighbors=n_neighbors, random_state=random_state\n",
    ")\n",
    "\n",
    "# Doc2vec already has document vectors\n",
    "embedding = reducer.fit_transform(\n",
    "    biorxiv_vec_df.dropna()[[f\"feat_{idx}\" for idx in range(300)]].values\n",
    ")\n",
    "\n",
    "umapped_df = (\n",
    "    pd.DataFrame(embedding, columns=[\"umap1\", \"umap2\"])\n",
    "    .assign(document=[str(tag) for tag in biorxiv_vec_df.dropna().document.values])\n",
    "    .merge(journal_map_df[[\"category\", \"document\", \"doi\"]], on=\"document\")\n",
    ")\n",
    "\n",
    "umapped_df.to_csv(\n",
    "    \"output/embedding_output/umap/biorxiv_umap_300_pretrained.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:annorxiver]",
   "language": "python",
   "name": "conda-env-annorxiver-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
