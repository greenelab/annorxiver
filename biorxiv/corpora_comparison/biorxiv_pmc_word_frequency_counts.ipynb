{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Pubmed Central Corpus with bioRxiv Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T15:35:08.603985Z",
     "start_time": "2020-05-16T15:35:08.005652Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import string\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../modules/\")\n",
    "\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from document_helper import dump_article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T15:35:09.118438Z",
     "start_time": "2020-05-16T15:35:08.605318Z"
    }
   },
   "outputs": [],
   "source": [
    "lemma_model = spacy.load(\"en_core_web_sm\")\n",
    "lemma_model.max_length = 9000000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Word Frequency of bioRxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T13:05:45.274025Z",
     "start_time": "2020-05-14T13:05:44.935047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doi</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10.1101/000026</td>\n",
       "      <td>000026_v1.xml</td>\n",
       "      <td>10.1101/000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10.1101/000042</td>\n",
       "      <td>000042_v1.xml</td>\n",
       "      <td>10.1101/000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10.1101/000067</td>\n",
       "      <td>000067_v1.xml</td>\n",
       "      <td>10.1101/000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10.1101/000091</td>\n",
       "      <td>000091_v1.xml</td>\n",
       "      <td>10.1101/000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10.1101/000109</td>\n",
       "      <td>000109_v1.xml</td>\n",
       "      <td>10.1101/000109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     document             doi\n",
       "doi                                          \n",
       "10.1101/000026  000026_v1.xml  10.1101/000026\n",
       "10.1101/000042  000042_v1.xml  10.1101/000042\n",
       "10.1101/000067  000067_v1.xml  10.1101/000067\n",
       "10.1101/000091  000091_v1.xml  10.1101/000091\n",
       "10.1101/000109  000109_v1.xml  10.1101/000109"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biorxiv_map_df = (\n",
    "    pd.read_csv(\"../exploratory_data_analysis/output/biorxiv_article_metadata.tsv\", sep=\"\\t\")\n",
    "    .groupby(\"doi\")\n",
    "    .agg({\"document\":\"first\", \"doi\":\"last\"})\n",
    ")\n",
    "biorxiv_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T13:05:45.304052Z",
     "start_time": "2020-05-14T13:05:45.275377Z"
    }
   },
   "outputs": [],
   "source": [
    "Path('output/biorxiv_word_counts').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:28:21.476606Z",
     "start_time": "2020-05-14T13:05:45.305380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70146668eb8342acb3f9055517a93f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=71118), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for document in tqdm_notebook(biorxiv_map_df.document.tolist()):\n",
    "    \n",
    "    document_text = dump_article_text(\n",
    "        file_path=f\"../biorxiv_articles/{document}\",\n",
    "        xpath_str=\"//abstract/p|//abstract/title|//body/sec//p|//body/sec//title\",\n",
    "        remove_stop_words=False\n",
    "    )\n",
    "\n",
    "    doc = lemma_model(\" \".join(document_text),  disable = ['ner', 'parser'])\n",
    "    tokens = [tok for tok in doc if tok.text.lower() not in string.punctuation]\n",
    "    \n",
    "    with open(f\"output/biorxiv_word_counts/{Path(document).stem}.tsv\", \"w\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"lemma\", \"count\"], delimiter=\"\\t\")\n",
    "        writer.writeheader()\n",
    "        \n",
    "        lemma_freq = Counter(\n",
    "            list(\n",
    "                map(\n",
    "                    lambda x: (\n",
    "                        x.lemma_.lower() \n",
    "                        if x.lemma_.lower() != '-pron-' \n",
    "                        else x.text.lower()\n",
    "                    ), \n",
    "                    tokens\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        writer.writerows([\n",
    "            {\"lemma\":val[0], \"count\":val[1]}\n",
    "            for val in lemma_freq.items()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Word Frequency of Pubmed Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T15:35:20.255824Z",
     "start_time": "2020-05-16T15:35:16.098522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1977651, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>article_type</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Environ_Health</td>\n",
       "      <td>research-article</td>\n",
       "      <td>10.1186/1476-069X-5-22</td>\n",
       "      <td>PMC1552054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Environ_Health</td>\n",
       "      <td>research-article</td>\n",
       "      <td>10.1186/1476-069X-4-12</td>\n",
       "      <td>PMC1226148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Environ_Health</td>\n",
       "      <td>research-article</td>\n",
       "      <td>10.1186/s12940-017-0316-3</td>\n",
       "      <td>PMC5635510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Environ_Health</td>\n",
       "      <td>research-article</td>\n",
       "      <td>10.1186/1476-069X-10-46</td>\n",
       "      <td>PMC3125232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Environ_Health</td>\n",
       "      <td>research-article</td>\n",
       "      <td>10.1186/1476-069X-11-91</td>\n",
       "      <td>PMC3533997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          journal      article_type                        doi       pmcid\n",
       "0  Environ_Health  research-article     10.1186/1476-069X-5-22  PMC1552054\n",
       "1  Environ_Health  research-article     10.1186/1476-069X-4-12  PMC1226148\n",
       "3  Environ_Health  research-article  10.1186/s12940-017-0316-3  PMC5635510\n",
       "4  Environ_Health  research-article    10.1186/1476-069X-10-46  PMC3125232\n",
       "5  Environ_Health  research-article    10.1186/1476-069X-11-91  PMC3533997"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmc_map_df = (\n",
    "    pd.read_csv(\n",
    "        \"../../pmc/exploratory_data_analysis/output/pubmed_central_journal_paper_map.tsv.xz\", \n",
    "        sep=\"\\t\"\n",
    "    )\n",
    "    .query(\"article_type=='research-article'\")\n",
    ")\n",
    "print(pmc_map_df.shape)\n",
    "pmc_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T15:35:20.269822Z",
     "start_time": "2020-05-16T15:35:20.257073Z"
    }
   },
   "outputs": [],
   "source": [
    "Path(\"output/pmc_word_counts\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T04:35:10.628132Z",
     "start_time": "2020-05-16T15:35:20.271026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572ec37fcdc74234801e5106327511b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1977651), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for document in tqdm_notebook(pmc_map_df[[\"journal\", \"pmcid\"]].values.tolist()):\n",
    "    \n",
    "    #Skip files that dont exist or files already parsed\n",
    "    if (\n",
    "        not Path(f\"../../pmc/journals/{document[0]}/{document[1]}.nxml\").exists()\n",
    "        or Path(f\"output/pmc_word_counts/{document[1]}.tsv\").exists()\n",
    "    ):\n",
    "        continue\n",
    "    \n",
    "    document_text = dump_article_text(\n",
    "        file_path=f\"../../pmc/journals/{document[0]}/{document[1]}.nxml\",\n",
    "        xpath_str=\"//abstract/sec/*|//body/sec/*\",\n",
    "        remove_stop_words=False\n",
    "    )\n",
    "    \n",
    "    doc = lemma_model(\" \".join(document_text),  disable = ['ner', 'parser'])\n",
    "    tokens = [tok for tok in doc if tok.text.lower() not in string.punctuation]\n",
    "    with open(f\"output/pmc_word_counts/{document[1]}.tsv\", \"w\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"lemma\", \"count\"],delimiter=\"\\t\")\n",
    "        writer.writeheader()\n",
    "\n",
    "        lemma_freq = Counter(\n",
    "            list(\n",
    "                map(\n",
    "                    lambda x: (\n",
    "                        x.lemma_.lower() \n",
    "                        if x.lemma_.lower() != '-pron-' \n",
    "                        else x.text.lower()\n",
    "                    ), \n",
    "                    tokens\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "              \n",
    "        writer.writerows([\n",
    "            {\"lemma\":val[0], \"count\":val[1]}\n",
    "            for val in lemma_freq.items()\n",
    "        ])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:annorxiver]",
   "language": "python",
   "name": "conda-env-annorxiver-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
