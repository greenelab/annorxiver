{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Pubmed Central Corpus with bioRxiv Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T15:31:55.121146Z",
     "start_time": "2020-08-07T15:31:54.460344Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import Counter\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from annorxiver_modules.document_helper import dump_article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T15:31:55.658944Z",
     "start_time": "2020-08-07T15:31:55.122472Z"
    }
   },
   "outputs": [],
   "source": [
    "lemma_model = spacy.load(\"en_core_web_sm\")\n",
    "lemma_model.max_length = 9000000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Word Frequency of bioRxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T21:50:25.846187Z",
     "start_time": "2020-07-28T21:50:25.619195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71118, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doi</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10.1101/000026</td>\n",
       "      <td>000026_v1.xml</td>\n",
       "      <td>10.1101/000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10.1101/000042</td>\n",
       "      <td>000042_v1.xml</td>\n",
       "      <td>10.1101/000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10.1101/000067</td>\n",
       "      <td>000067_v1.xml</td>\n",
       "      <td>10.1101/000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10.1101/000091</td>\n",
       "      <td>000091_v1.xml</td>\n",
       "      <td>10.1101/000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10.1101/000109</td>\n",
       "      <td>000109_v1.xml</td>\n",
       "      <td>10.1101/000109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     document             doi\n",
       "doi                                          \n",
       "10.1101/000026  000026_v1.xml  10.1101/000026\n",
       "10.1101/000042  000042_v1.xml  10.1101/000042\n",
       "10.1101/000067  000067_v1.xml  10.1101/000067\n",
       "10.1101/000091  000091_v1.xml  10.1101/000091\n",
       "10.1101/000109  000109_v1.xml  10.1101/000109"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biorxiv_map_df = (\n",
    "    pd.read_csv(\"../exploratory_data_analysis/output/biorxiv_article_metadata.tsv\", sep=\"\\t\")\n",
    "    .groupby(\"doi\")\n",
    "    .agg({\"document\":\"first\", \"doi\":\"last\"})\n",
    ")\n",
    "print(biorxiv_map_df.shape)\n",
    "biorxiv_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T21:50:25.860643Z",
     "start_time": "2020-07-28T21:50:25.847547Z"
    }
   },
   "outputs": [],
   "source": [
    "Path(\"output/biorxiv_word_counts/\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T07:17:25.743500Z",
     "start_time": "2020-07-28T21:50:25.861928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71118/71118 [9:26:59<00:00,  2.09it/s]   \n"
     ]
    }
   ],
   "source": [
    "sentence_length = {}\n",
    "for document in tqdm(biorxiv_map_df.document.tolist()):\n",
    "    \n",
    "    document_text = dump_article_text(\n",
    "        file_path=f\"../biorxiv_articles/{document}\",\n",
    "        xpath_str=\"//abstract/p|//abstract/title|//body/sec//p|//body/sec//title\",\n",
    "        remove_stop_words=False\n",
    "    )\n",
    "\n",
    "    doc = lemma_model(\n",
    "        \" \".join(document_text),  \n",
    "        disable = ['ner']\n",
    "    )\n",
    "    \n",
    "    tokens = [\n",
    "        (str(tok).lower(), tok.pos_, tok.dep_) \n",
    "        for tok in doc \n",
    "        if tok.text.lower() not in string.punctuation\n",
    "    ]\n",
    "    \n",
    "    sentence_length[document] = [len(sent) for sent in doc.sents]\n",
    "    \n",
    "    with open(f\"output/biorxiv_word_counts/{document}.tsv\", \"w\") as file:\n",
    "        writer = csv.DictWriter(\n",
    "            file, fieldnames=[\"lemma\", \"pos_tag\", \"dep_tag\", \"count\"],\n",
    "            delimiter=\"\\t\"\n",
    "        )\n",
    "        \n",
    "        writer.writeheader()\n",
    "    \n",
    "        lemma_stats = Counter(tokens)          \n",
    "        writer.writerows([\n",
    "            {\n",
    "                \"lemma\":val[0][0],\n",
    "                \"pos_tag\":val[0][1],\n",
    "                \"dep_tag\":val[0][2],\n",
    "                \"count\":val[1]\n",
    "            }\n",
    "            for val in lemma_stats.items()\n",
    "        ])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T07:17:26.142741Z",
     "start_time": "2020-07-29T07:17:25.744607Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    sentence_length, \n",
    "    open(\"output/biorxiv_sentence_length.pkl\", \"wb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Word Frequency of Pubmed Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T15:32:08.282109Z",
     "start_time": "2020-08-07T15:32:04.097010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1977651, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>article_type</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Environ_Health</td>\n",
       "      <td>research-article</td>\n",
       "      <td>10.1186/1476-069X-5-22</td>\n",
       "      <td>PMC1552054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Environ_Health</td>\n",
       "      <td>research-article</td>\n",
       "      <td>10.1186/1476-069X-4-12</td>\n",
       "      <td>PMC1226148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Environ_Health</td>\n",
       "      <td>research-article</td>\n",
       "      <td>10.1186/s12940-017-0316-3</td>\n",
       "      <td>PMC5635510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Environ_Health</td>\n",
       "      <td>research-article</td>\n",
       "      <td>10.1186/1476-069X-10-46</td>\n",
       "      <td>PMC3125232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Environ_Health</td>\n",
       "      <td>research-article</td>\n",
       "      <td>10.1186/1476-069X-11-91</td>\n",
       "      <td>PMC3533997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          journal      article_type                        doi       pmcid\n",
       "0  Environ_Health  research-article     10.1186/1476-069X-5-22  PMC1552054\n",
       "1  Environ_Health  research-article     10.1186/1476-069X-4-12  PMC1226148\n",
       "3  Environ_Health  research-article  10.1186/s12940-017-0316-3  PMC5635510\n",
       "4  Environ_Health  research-article    10.1186/1476-069X-10-46  PMC3125232\n",
       "5  Environ_Health  research-article    10.1186/1476-069X-11-91  PMC3533997"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmc_map_df = (\n",
    "    pd.read_csv(\n",
    "        \"../../pmc/exploratory_data_analysis/output/pubmed_central_journal_paper_map.tsv.xz\", \n",
    "        sep=\"\\t\"\n",
    "    )\n",
    "    .query(\"article_type=='research-article'\")\n",
    ")\n",
    "print(pmc_map_df.shape)\n",
    "pmc_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T18:44:26.716752Z",
     "start_time": "2020-08-02T18:44:26.703499Z"
    }
   },
   "outputs": [],
   "source": [
    "Path(\"../../pmc/pmc_corpus/pmc_word_counts/\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-02T18:44:22.284Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 1362827/1977651 [58:02:12<55:23:48,  3.08it/s]  "
     ]
    }
   ],
   "source": [
    "sentence_length = {}\n",
    "for document in tqdm(pmc_map_df[[\"journal\", \"pmcid\"]].values.tolist()):\n",
    "    \n",
    "    #Skip files that dont exist or files already parsed\n",
    "    if (\n",
    "        not Path(f\"../../pmc/journals/{document[0]}/{document[1]}.nxml\").exists()\n",
    "        or Path(f\"../../pmc/pmc_corpus/pmc_word_counts/{document[1]}.tsv\").exists()\n",
    "    ):\n",
    "        continue\n",
    "    \n",
    "    document_text = dump_article_text(\n",
    "        file_path=f\"../../pmc/journals/{document[0]}/{document[1]}.nxml\",\n",
    "        xpath_str=\"//abstract/sec/*|//body/sec/*\",\n",
    "        remove_stop_words=False\n",
    "    )\n",
    "    \n",
    "    doc = lemma_model(\n",
    "        \" \".join(document_text),  \n",
    "        disable = ['ner']\n",
    "    )\n",
    "    \n",
    "    tokens = [\n",
    "        (str(tok).lower(), tok.pos_, tok.dep_) \n",
    "        for tok in doc \n",
    "        if tok.text.lower() not in string.punctuation\n",
    "    ]\n",
    "    \n",
    "    sentence_length[document[1]] = [len(sent) for sent in doc.sents]\n",
    "    \n",
    "    with open(f\"../../pmc/pmc_corpus/pmc_word_counts/{document[1]}.tsv\", \"w\") as file:\n",
    "        writer = csv.DictWriter(\n",
    "            file, fieldnames=[\"lemma\", \"pos_tag\", \"dep_tag\", \"count\"],\n",
    "            delimiter=\"\\t\"\n",
    "        )\n",
    "        \n",
    "        writer.writeheader()\n",
    "    \n",
    "        lemma_stats = Counter(tokens)          \n",
    "        writer.writerows([\n",
    "            {\n",
    "                \"lemma\":val[0][0],\n",
    "                \"pos_tag\":val[0][1],\n",
    "                \"dep_tag\":val[0][2],\n",
    "                \"count\":val[1]\n",
    "            }\n",
    "            for val in lemma_stats.items()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-06T14:24:46.037Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    sentence_length, \n",
    "    open(\"../../pmc/pmc_corpus/pmc_sentence_length.pkl\", \"wb\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:annorxiver]",
   "language": "python",
   "name": "conda-env-annorxiver-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
